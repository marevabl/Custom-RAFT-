import torch
import torch.nn as nn
import torch.nn.functional as F

from layers.Retrieval import RetrievalTool

class Model(nn.Module):
    """
    Paper link: https://arxiv.org/pdf/2205.13504.pdf
    """
    
    def __init__(self, configs, individual=False):
        """
        individual: Bool, whether shared model among different variates.
        """
        super(Model, self).__init__()
       
        if getattr(configs, "use_gpu", False) and torch.cuda.is_available():
         # use configs.gpu if present, otherwise default to 0
          gpu_id = getattr(configs, "gpu", 0)
          self.device = torch.device(f"cuda:{gpu_id}")
        else:
          # fall back to CPU
          self.device = torch.device("cpu")
            
        self.task_name = getattr(configs, "task_name", "long_term_forecast")
        self.seq_len = configs.seq_len
        if self.task_name == 'classification' or self.task_name == 'anomaly_detection' or self.task_name == 'imputation':
            self.pred_len = configs.seq_len
        else:
            self.pred_len = configs.pred_len
        # Series decomposition block from Autoformer
#         self.decompsition = series_decomp(configs.moving_avg)
#         self.individual = individual
        self.channels = configs.enc_in

        self.linear_x = nn.Linear(self.seq_len, self.pred_len)
        
        self.n_period = configs.n_period
        self.topm = configs.topm
        
        self.rt = RetrievalTool(
            seq_len=self.seq_len,
            pred_len=self.pred_len,
            channels=self.channels,
            n_period=self.n_period,
            topm=self.topm,
        )
        
        self.period_num = self.rt.period_num[-1 * self.n_period:]
        
        module_list = [
            nn.Linear(self.pred_len // g, self.pred_len)
            for g in self.period_num
        ]
        self.retrieval_pred = nn.ModuleList(module_list)
        self.linear_pred = nn.Linear(2 * self.pred_len, self.pred_len)

#         if self.task_name == 'classification':
#             self.projection = nn.Linear(
#                 configs.enc_in * configs.seq_len, configs.num_class)

    def prepare_dataset(self, train_data, valid_data, test_data):
        self.rt.prepare_dataset(train_data)
        
        self.retrieval_dict = {}
        
        print('Doing Train Retrieval')
        train_rt = self.rt.retrieve_all(train_data, train=True, device=self.device)

        print('Doing Valid Retrieval')
        valid_rt = self.rt.retrieve_all(valid_data, train=False, device=self.device)

        print('Doing Test Retrieval')
        test_rt = self.rt.retrieve_all(test_data, train=False, device=self.device)

        del self.rt
        torch.cuda.empty_cache()
            
        self.retrieval_dict['train'] = train_rt.detach()
        self.retrieval_dict['valid'] = valid_rt.detach()
        self.retrieval_dict['test'] = test_rt.detach()

    def encoder(self, x, index, mode):
        """Core RAFT encoder used for forecasting / imputation / etc."""
        # Keep indices on CPU because retrieval_dict is stored on CPU
        if hasattr(index, "device") and index.device.type != "cpu":
            index = index.cpu()

        _, num_windows, _, _ = self.retrieval_dict[mode].shape
        index = index.clamp(min=0, max=num_windows - 1)
        
        bsz, seq_len, channels = x.shape
        # Ensure sequence and channel sizes match configuration
        assert seq_len == self.seq_len and channels == self.channels

        # Normalize by last value to stabilize training
        x_offset = x[:, -1:, :].detach()
        x_norm = x - x_offset

        # Prediction from the current sequence only
        x_pred_from_x = self.linear_x(x_norm.permute(0, 2, 1)).permute(0, 2, 1)  # [B, P, C]

        # Prediction from retrieval bank (stored per mode: 'train', 'valid', 'test')
        pred_from_retrieval = self.retrieval_dict[mode][:, index]  # [G, B, P, C]
        pred_from_retrieval = pred_from_retrieval.to(self.device)

        retrieval_pred_list = []

        for i, pr in enumerate(pred_from_retrieval):
            # pr expected shape: (batch_size, pred_len, channels)
            assert pr.shape == (bsz, self.pred_len, channels)

            g = self.period_num[i]                # period (e.g. 8, 4, 2, 1)
            pr = pr.reshape(bsz, self.pred_len // g, g, channels)
            pr = pr[:, :, 0, :]                   # take one location in each group

            pr = self.retrieval_pred[i](pr.permute(0, 2, 1)).permute(0, 2, 1)
            pr = pr.reshape(bsz, self.pred_len, self.channels)

            retrieval_pred_list.append(pr)

        # Aggregate across all periods
        retrieval_pred_list = torch.stack(retrieval_pred_list, dim=1)  # [B, G, P, C]
        retrieval_pred_list = retrieval_pred_list.sum(dim=1)           # [B, P, C]

        # Combine with prediction from x and denormalize
        retrieval_pred_list = retrieval_pred_list + x_pred_from_x
        retrieval_pred_list = retrieval_pred_list + x_offset

        return retrieval_pred_list

    def forecast(self, x_enc, index, mode):
        # Encoder
        return self.encoder(x_enc, index, mode)

    def imputation(self, x_enc, index, mode):
        # Encoder
        return self.encoder(x_enc, index, mode)

    def anomaly_detection(self, x_enc, index, mode):
        # Encoder
        return self.encoder(x_enc, index, mode)

    def classification(self, x_enc, index, mode):
        # Encoder
        enc_out = self.encoder(x_enc, index, mode)
        # Output
        # (batch_size, seq_length * d_model)
        output = enc_out.reshape(enc_out.shape[0], -1)
        # (batch_size, num_classes)
        output = self.projection(output)
        return output

    def forward(self, x_enc, index, mode='train'):
        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':
            dec_out = self.forecast(x_enc, index, mode)
            return dec_out[:, -self.pred_len:, :]  # [B, L, D]
        if self.task_name == 'imputation':
            dec_out = self.imputation(x_enc, index, mode)
            return dec_out  # [B, L, D]
        if self.task_name == 'anomaly_detection':
            dec_out = self.anomaly_detection(x_enc, index, mode)
            return dec_out  # [B, L, D]
        if self.task_name == 'classification':
            dec_out = self.classification(x_enc, index, mode)
            return dec_out  # [B, N]
        return None
